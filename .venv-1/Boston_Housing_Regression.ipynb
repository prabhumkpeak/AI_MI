{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b05383d",
   "metadata": {},
   "source": [
    "\n",
    "# Regression Analysis with Boston Housing Dataset\n",
    "\n",
    "This notebook covers different regression techniques using the **Boston Housing Dataset**.  \n",
    "We will go step by step, starting with **Simple Linear Regression**, then **Multiple Linear Regression**, **Polynomial Regression**, and finally **Regularized Regression (Ridge, Lasso, ElasticNet)**.  \n",
    "\n",
    "At the end, we will also cover **Evaluation Metrics** (MSE, RMSE, MAE, RÂ² score) and the **assumptions** to check before interpreting regression results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa52028f",
   "metadata": {},
   "source": [
    "\n",
    "## Step 1: Load the Dataset\n",
    "\n",
    "We will use the **Boston Housing dataset** available in `sklearn.datasets`.  \n",
    "This dataset contains information about houses in Boston and their prices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5702d398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  PRICE  \n",
       "0    -122.23  4.526  \n",
       "1    -122.22  3.585  \n",
       "2    -122.24  3.521  \n",
       "3    -122.25  3.413  \n",
       "4    -122.25  3.422  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load Boston Housing dataset directly\n",
    "url = \"https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Display the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7860ec",
   "metadata": {},
   "source": [
    "\n",
    "## Step 2: Simple Linear Regression\n",
    "\n",
    "We start with **one independent variable** (e.g., RM = average number of rooms per dwelling) to predict the house price.\n",
    "\n",
    "**Steps:**\n",
    "1. Select `RM` as the independent variable (X) and `PRICE` as the dependent variable (y).\n",
    "2. Fit a linear regression model.\n",
    "3. Plot the regression line.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5d0abc",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['RM'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n\u001b[1;32m----> 5\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRM\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      6\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPRICE\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      8\u001b[0m lin_reg \u001b[38;5;241m=\u001b[39m LinearRegression()\n",
      "File \u001b[1;32mc:\\Users\\admin\\IITDelhiAIML\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\admin\\IITDelhiAIML\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\admin\\IITDelhiAIML\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[0;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[1;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['RM'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = df[['RM']]\n",
    "y = df['PRICE']\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X, y)\n",
    "\n",
    "# Predictions\n",
    "y_pred = lin_reg.predict(X)\n",
    "\n",
    "# Visualization\n",
    "plt.scatter(X, y, alpha=0.5)\n",
    "plt.plot(X, y_pred, color='red', linewidth=2)\n",
    "plt.xlabel('Average Number of Rooms (RM)')\n",
    "plt.ylabel('House Price')\n",
    "plt.title('Simple Linear Regression (RM vs Price)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3c0f80",
   "metadata": {},
   "source": [
    "\n",
    "## Step 3: Multiple Linear Regression\n",
    "\n",
    "Now we use **all available features** to predict house prices.\n",
    "\n",
    "**Steps:**\n",
    "1. Use all columns except PRICE as independent variables (X).\n",
    "2. Fit a linear regression model.\n",
    "3. Evaluate using metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7e7cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df.drop('PRICE', axis=1)\n",
    "y = df['PRICE']\n",
    "\n",
    "mlr = LinearRegression()\n",
    "mlr.fit(X, y)\n",
    "\n",
    "y_pred_mlr = mlr.predict(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0f25b0",
   "metadata": {},
   "source": [
    "\n",
    "## Step 4: Polynomial Regression\n",
    "\n",
    "Sometimes relationships are **non-linear**.  \n",
    "Polynomial regression allows us to capture such relationships by including powers of the features.\n",
    "\n",
    "**Steps:**\n",
    "1. Use `RM` again as the predictor.\n",
    "2. Transform it into polynomial features (degree=2).\n",
    "3. Fit a regression model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902e6073",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(df[['RM']])\n",
    "\n",
    "lin_reg2 = LinearRegression()\n",
    "lin_reg2.fit(X_poly, y)\n",
    "\n",
    "y_poly_pred = lin_reg2.predict(X_poly)\n",
    "\n",
    "plt.scatter(df['RM'], y, alpha=0.5)\n",
    "plt.scatter(df['RM'], y_poly_pred, color='red', s=10)\n",
    "plt.xlabel('Average Number of Rooms (RM)')\n",
    "plt.ylabel('House Price')\n",
    "plt.title('Polynomial Regression (Degree=2)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df14207",
   "metadata": {},
   "source": [
    "\n",
    "## Step 5: Regularized Regression\n",
    "\n",
    "Regularization is used to prevent **overfitting** by adding a penalty term to the regression.\n",
    "\n",
    "- **Ridge Regression:** L2 penalty (squares of coefficients).\n",
    "- **Lasso Regression:** L1 penalty (absolute value of coefficients, can shrink some to 0).\n",
    "- **ElasticNet Regression:** Combination of L1 + L2 penalties.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df0a66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X, y)\n",
    "\n",
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X, y)\n",
    "\n",
    "elastic = ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
    "elastic.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcbe114",
   "metadata": {},
   "source": [
    "\n",
    "## Step 6: Evaluation Metrics\n",
    "\n",
    "We evaluate regression models using:\n",
    "\n",
    "- **Mean Squared Error (MSE):** Average of squared errors.\n",
    "- **Root Mean Squared Error (RMSE):** Square root of MSE (more interpretable).\n",
    "- **Mean Absolute Error (MAE):** Average of absolute errors.\n",
    "- **RÂ² Score:** Proportion of variance explained by the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675f7a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "mse = mean_squared_error(y, y_pred_mlr)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y, y_pred_mlr)\n",
    "r2 = r2_score(y, y_pred_mlr)\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"RÂ² Score:\", r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c370bd54",
   "metadata": {},
   "source": [
    "\n",
    "## Step 7: Verify Assumptions Before Interpreting Results\n",
    "\n",
    "Linear regression makes several assumptions:\n",
    "\n",
    "1. **Linearity:** Relationship between predictors and response is linear.\n",
    "2. **Independence:** Residuals are independent.\n",
    "3. **Homoscedasticity:** Constant variance of residuals.\n",
    "4. **Normality of Residuals:** Errors should be normally distributed.\n",
    "\n",
    "We check residual plots to validate assumptions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841513fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "residuals = y - y_pred_mlr\n",
    "\n",
    "sns.scatterplot(x=y_pred_mlr, y=residuals)\n",
    "plt.axhline(y=0, color='red', linestyle='--')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot')\n",
    "plt.show()\n",
    "\n",
    "sns.histplot(residuals, kde=True)\n",
    "plt.title('Distribution of Residuals')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IITDelhiAIML (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
